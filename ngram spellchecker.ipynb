{
 "metadata": {
  "name": "ngram spellchecker"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#CHRISTOPHER M. CHURCH\n#ASSISTANT PROFESSOR OF HISTORY\n#UNIVERSITY OF NEVADA, RENO\n\nimport re, collections, csv\nfrom math import log\n\nwd = \"/home/cmchurch/Desktop/ngram-work/\"\nalphabet = 'abcdefghijklmnopqrstuvwxyz\u00f9\u00e0\u00e2\u00fb\u00fc\u00e6\u00e7\u00e9\u00e8\u00ea\u00eb\u00ef\u00ee\u00f4\u0153ABCDEFGHIJKLMNOPQRSTUVWXYZ\u00d9\u00c0\u00c2\u00db\u00dc\u00c6\u00c7\u00c9\u00c8\u00ca\u00cb\u00cf\u00ce\u00d4\u0152'\nalpharegex = r\"[\" + re.escape(alphabet) + r\"]\\S+\"\ntrained_data=\"google-n-gram.txt\"\n#trained_data=\"lexique-with-freq.tsv\"",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#adapted from PETER NORVIG SPELLCHECKER (http://norvig.com/spell-correct.html)\n\n\ndef tokenize(text):\n    return re.findall(alpharegex,text)\n\ndef readgrams(f):\n    with open(wd + f,'r') as tsvin:\n        tsvin = csv.reader (tsvin, delimiter=\"\\t\")\n        model = collections.defaultdict(lambda: 1)\n        for row in tsvin:\n            #print row[0],row[1]\n            model[row[0]]+=float(row[1])\n        return model\n    \nNWORDS = readgrams(trained_data)\n\ndef edits1(word):\n   splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n   deletes    = [a + b[1:] for a, b in splits if b]\n   transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)>1]\n   replaces   = [a + c + b[1:] for a, b in splits for c in alphabet if b]\n   inserts    = [a + c + b     for a, b in splits for c in alphabet]\n   return set(deletes + transposes + replaces + inserts)\n\ndef known_edits2(word):\n    return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in NWORDS)\n\ndef known(words): return set(w for w in words if w in NWORDS)\n\ndef correct(word):\n    candidates = known([word]) or known(edits1(word)) or known_edits2(word) or [word]\n    return max(candidates, key=NWORDS.get)\n\ndef strip_newlines(text):\n    return text.replace('\\n',' ')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#following code from http://stackoverflow.com/questions/8870261/how-to-split-text-without-spaces-into-list-of-words\n#somehow combine this with unmatched candidates to see if they could be broken into two words?\n\n#words = NWORDS #use the same trained data as above\ndata=\"lexique-with-freq.tsv\" #changed it to use lexique data for splitter and ngrams data for spell corrector\nwords = readgrams(data)\n\nwordcost = dict((k, log((i+1)*log(len(words)))) for i,k in enumerate(words))\nmaxword = max(len(x) for x in words)\n\ndef infer_spaces(s):\n    \"\"\"Uses dynamic programming to infer the location of spaces in a string\n    without spaces.\"\"\"\n\n    # Find the best match for the i first characters, assuming cost has\n    # been built for the i-1 first characters.\n    # Returns a pair (match_cost, match_length).\n    def best_match(i):\n        candidates = enumerate(reversed(cost[max(0, i-maxword):i]))\n        return min((c + wordcost.get(s[i-k-1:i], 9e999), k+1) for k,c in candidates)\n\n    # Build the cost array.\n    cost = [0]\n    for i in range(1,len(s)+1):\n        c,k = best_match(i)\n        cost.append(c)\n\n    # Backtrack to recover the minimal-cost string.\n    out = []\n    i = len(s)\n    while i>0:\n        c,k = best_match(i)\n        assert c == cost[i]\n        out.append(s[i-k:i])\n        i -= k\n\n    return \" \".join(reversed(out))",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "sample_text= \"\"\"TtxTE. \u2014 Avis de P\u00e9d\u00eeteur. \u2014 Aventures p\u00e9rilleuses d'un marin fran\u00e7ais dans la Nom\nvalwglin\u00e8g, u. Une Course de taiaresux \u00e0 Mndrid. \u2014 Christophe Colomb,\u2018 sa vie et\nses d\u00e8muve\ufb02em ..... gn bpumnau {and de la mer. -- G\u00e9ographie du d\u00e9partement de\nrgiu\ufb02- Le Tour Il! la \u2018ferre en qunire-\u2018ringts r\u00e9cits. \u2014 Curiosit\u00e9s g\u00e9ographiques. \u2014-\nChroiique. l . i l ' \"\"\"\n",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "sample_text=\"\"\"Ma vie, \u00e0 partir de cette \u00e9poque,\n\nfut celle de tous les marins. J'aimais -\n\nle m\u00e9tier que j'avais choisi et, \u00e0. \u2018l'\u00e2ge\nde 21 dans, je servais en _qu_a1it\u00e9. de lieu-\ntenant sous les ordres de Philippe qui i,\nplus \u00e2g\u00e9 que moi, \u00e9tait devenu plecapi-\ntainede I\u00ceESp\u00e9rancc. Nous avions con-y.\nserve -l'un pour l'autre notre amiti\u00e9\u00bb\nd'enfance que, pendant tout ce temps,\n\nun seul nuage \u00e9tait venutroubler : je a  \n\nm'\u00e9tais faitrecevoirfranc-ma\u00e7jonepAne\ngleterre, et lorsque, longtempsapr\u00e8s,\n\nje Fappris \u00e0 Phil-ippe,il entra d\u00efans\ufb01-yner dansllalbaiede\nune col\u00e8re tellement violente q+\u00fce_\ufb01j_a_\n\ncrus de ma dignit\u00e9 de quitter son lrgord. \n\nMais au bout de quelques jours mon\n\nami vint me chercher, et nous e\u00fbmes\nbien vite oubli\u00e9 ce l\u00e9ger dilf\u00e9remd\u00fft,\"\"\"",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "sample_text=\"\"\"ruina lerpouvoir usurpe de Tallxouns ou\n\u2018Shogouns, \u2018et releva l\u2019autorite du Mikado.\n.Chaque ann\u00e9e, des l\u2018\u00eates viennent-rappeler\nl\u2019anniversaire de cette r\u00e9volutionJLes re-\njou\u2018issances durent trois jours, comme\u2014r\nautlef\u2018ois chez nous pounles \u2018Erois.__Glo-\nrieuses. La\u2019premi\u00e8re journ\u00e9e est remplie\npar les courses de chemuxplauseconde\npar un \u2019feu d\u2019arti\ufb01ce\u2019tir\u00e9 en plein,sole\u00eel,\navec gel-Les de \u2018fumce mu\u00cfticolore\u00cb\u2018Le-\ntroisi\u00e8n\ufb01e\u2018jour qppantient aux. \u00abSouin\u00f4s \u00bb\nou luueurs. * t \u201cI\"\"\"",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "cleaned_text = re.sub(u'[^a-zA-Z0-9\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00e0\u00e8\u00ec\u00f2\u00f9\u00c0\u00c8\u00cc\u00d2\u00d9\u00e2\u00ea\u00ee\u00f4\u00c2\u00ca\u00ce\u00d4\u00e3\u00f5\u00c3\u00d5\u00cf\u00e7\u00c7:\\-\\' ]', ' ', sample_text.lower().decode('utf8'))\n#cleaned_text = cleaned_text.replace(r'-\\s','')\ntokens = tokenize(cleaned_text)\nprint tokens",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[u'ma', u'vie', u'partir', u'de', u'cette', u'poque', u'fut', u'celle', u'de', u'tous', u'les', u'marins', u\"j'aimais\", u'le', u'm\\xe9tier', u'que', u\"j'avais\", u'choisi', u'et', u\"l'\\xe2ge\", u'de', u'dans', u'je', u'servais', u'en', u'qu', u'a1it\\xe9', u'de', u'lieu-', u'tenant', u'sous', u'les', u'ordres', u'de', u'philippe', u'qui', u'plus', u'g\\xe9', u'que', u'moi', u'tait', u'devenu', u'plecapi-', u'tainede', u'i\\xceesp\\xe9rancc', u'nous', u'avions', u'con-y', u'serve', u\"l'un\", u'pour', u\"l'autre\", u'notre', u'amiti\\xe9', u\"d'enfance\", u'que', u'pendant', u'tout', u'ce', u'temps', u'un', u'seul', u'nuage', u'tait', u'venutroubler', u'je', u\"m'\\xe9tais\", u'faitrecevoirfranc-ma\\xe7jonepane', u'gleterre', u'et', u'lorsque', u'longtempsapr\\xe8s', u'je', u'fappris', u'phil-ippe', u'il', u'entra', u'ans', u'yner', u'dansllalbaiede', u'une', u'col\\xe8re', u'tellement', u'violente', u'crus', u'de', u'ma', u'dignit\\xe9', u'de', u'quitter', u'son', u'lrgord', u'mais', u'au', u'bout', u'de', u'quelques', u'jours', u'mon', u'ami', u'vint', u'me', u'chercher', u'et', u'nous', u'mes', u'bien', u'vite', u'oubli\\xe9', u'ce', u'l\\xe9ger', u'dilf\\xe9remd']\n"
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "newtext=\"\"\n\nfor token in tokens:\n    best_candidate = correct(token.encode('utf8'))\n    #print token + \", \"+ best_candidate.decode('utf8')\n    if (token.encode('utf8')==best_candidate):\n        breakword=infer_spaces(best_candidate)\n        if (len(breakword.split(' ')) < 4):\n            best_candidate=breakword\n    newtext+=best_candidate.decode('utf8')+\" \"\nprint newtext",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "ma vie partir de cette poque fut celle de tous les marins j'aimais le m\u00e9tier que j'avais choisi et l' g e de dans je servais en qu agit\u00e9 de lieu tenant sous les ordres de phi lippe qui plus que moi tait devenu le cap i tain e d i\u00ceesp\u00e9rancc nous avions con d y serve l'un pour l' autre notre amiti\u00e9 i'enfance que pendant tout ce temps un seul nuage tait venu troubler je m'\u00e9tais faitrecevoirfranc-ma\u00e7jonepane le terre et lorsque longtemps apr\u00e8s je appris phi lippe il entra ans ne r dansllalbaiede une col\u00e8re tellement violente crus de ma dignit\u00e9 de quitter son lord mais au bout de quelques jours mon ami vint me chercher et nous mes bien vite oubli\u00e9 ce l\u00e9ger dilf\u00e9rend \n"
      }
     ],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}